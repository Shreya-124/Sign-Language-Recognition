# Sign-Language-Recognition
This is a Sign Language Recognition Project based on Convolutional Neural Network.<br/>
This is a team Project we made as part of our third year Minor.<br/> 
Technologies Involved:
<ol>
<li><b>Python Interpreter 3.7.2</b></li>
<li><b>OpenCV</b></li>
<li><b>PyQT5</b></li>
<li><b>Tensorflow Framework</b></li>
<li><b>Keras API</b></li>
</ol>
For the detection of movement of gesture, cv2 library is used and an external camera as a hardware requirement is needed.<br/>
The frontend is built on PyQT5 which comprise of a module that simply detects the gesture and displays appropriate alphabet.<br/>
Concerning to the implementation,TensorFlow framework with keras API has been used.
<br/>
The dataset is taken from: <a href="https://www.kaggle.com/datamunge/sign-language-mnist">https://www.kaggle.com/datamunge/sign-language-mnist</a><br/>
The data includes approximately 35,000 28x28 pixel images of the 24 letters of the alphabet.
</br>
<b>Have a look at our introductory gif</b>
  
 ![sign](https://user-images.githubusercontent.com/58930225/88955142-259c3b80-d2b9-11ea-81d9-d71f36e14f1a.gif)
 <br/>
 The model is trained using the dataset and hence it comes out to be 92.3% accurate.<br/>
 All code files are provided for reference.
